# fgrep-problem-benchmarks

The "fgrep problem" is to match a set of fixed strings in a corpus.  The
matching can be done "in parallel" by a DFA.

There are various methods to generate the DFA.

See the top of `fixed-strings.sh` for instructions on running these benchmarks.

[Lobste.rs Discussion about Aho-Corasick Algorithm](https://lobste.rs/s/fq8uil/aho_corasick)

## Visualization

Simple DFA for `"do" | "done" | "break"`.  See below for the DFA for the bigger
benchmark problem.

![Simpler DFA](https://raw.githubusercontent.com/oilshell/blog-code/master/fgrep-problem-benchmarks/_gen/trie.png)

## Description of the Problem and the re2c Solution

```
Matching this file:
-rw-rw-r-- 1 andy andy 338M Nov 10 11:09 _tmp/all-10.txt

Against 13 keywords:
   for while continue break if fi then else elif case esac do done
```

- [DFA for fixed-strings.re2.cc](//raw.githubusercontent.com/oilshell/blog-code/master/fgrep-problem-benchmarks/_gen/fixed-strings.png)
- [Source generated by
re2c from fixed-strings.re2c.cc](//github.com/oilshell/blog-code/blob/master/fgrep-problem-benchmarks/_gen/fixed-strings.cc)
Note that there are ~35 states `yy2` - `yy36`.
- [Native code stats for
  fixed-strings.re2c.cc](//raw.githubusercontent.com/oilshell/blog-code/master/fgrep-problem-benchmarks/_gen/code-size.txt).
  `GrepFixedStrings()` is compiled to 791 bytes of native code.  It has one or
  two variables, so all of them should fix in registers.

## Approximate Benchmark Results

| Benchmark | User Space Time (ms) | Real Time (ms) |
| --- | ---: | ---: |
| cat | 0 | 46 |
| wc -l | 139 | 189 |
| fgrep | 1,368  | 1,432 |
| grep | 1,093 | 1,133 |
| read:count-lines (touch every byte in C++) | 49 | 186 |
| read:fixed-strings (match with re2c) | 1,211 | 1,347 |
| Python re | 5,781 | 5,946 |

NOTE: Each benchmarks matches the same set of strings, but the output is
slightly different.  I did enough experiments to convince myself that this
doesn't matter.  Aside from I/O, which we've accounted for, **matching** is the
lion's share of the work, not say printing lines.

## Observations

- grep is faster than native code!  I think this is because doesn't touch every
  byte.  It knows how to skip bytes in the fashion of Boyer-Moore.  See links
  below.
- I think that Python is slower because it's a Perl-style **backtracking
  engine** rather than an automata-based angine.

### Links

- [Why GNU Grep is Fast](https://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html) ([Discussions](https://news.ycombinator.com/item?id=12351140))
- [aho-corasick](https://github.com/BurntSushi/aho-corasick) library in Rust.

### TODO

- Measure running time of other regex implementations on the same problem.
  (Pull requests accepted.)
  - Are all backtracking engines slower than automata-based engines?
  - Does interpreting vs. compiling make a difference?  `grep` is an
    interpreter but it beats a compiler, probably due to the strings it does
    **not** try to match.
  - RE2, Rust, Go?
- Plot running time vs. number of strings.  Right now we have a fixed set of 13
  strings.  It would be nice to do 2, 10, 20, 30, etc.

